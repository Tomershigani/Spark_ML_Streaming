# Real-time Data Processing with Spark Streaming and Random Forest
In this project, I leveraged the power of Spark Streaming to extract and process big data from a data source in real-time.
Specifically, I used Spark Streaming to train and test a Random Forest model while the data was being streamed.

The project involved several steps, including setting up a data source and a Spark Streaming context, defining the schema for the data, 
and configuring the model parameters. Once these steps were completed, I used Spark Streaming to continuously pull and process data in batches, 
train the Random Forest model, and evaluate its performance on the fly.

This real-time approach enabled me to detect and respond to changes in the data as they occurred, making it ideal for scenarios where the data is
constantly evolving or where timely decisions need to be made based on the data. The use of the Random Forest model allowed me to efficiently handle 
and process the large volume of data, while also providing accurate and reliable predictions.

Overall, this project demonstrates the power of Spark Streaming for real-time data processing and highlights the value of using machine
learning models like Random Forest to extract insights and make informed decisions from big data.

<img src="https://user-images.githubusercontent.com/81327428/221788206-66b1f8cc-6cb2-4a04-84a9-78642909ac2f.png" width="100" height="100">      <img src="https://user-images.githubusercontent.com/81327428/221789132-1d1b8f96-ded1-465e-97c9-0ee659070b4b.png" width="200" height="100">     <img src="https://user-images.githubusercontent.com/81327428/221789580-9cc3fa37-cd40-4e75-a9da-343fa4f623d5.png" width="100" height="100">
